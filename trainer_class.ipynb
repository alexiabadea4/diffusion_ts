{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexia\\anaconda3\\envs\\oneddif\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gluonts.core.component import validated\n",
    "import wandb\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, dim, proj_dim, max_steps=256):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\n",
    "            \"embedding\", self._build_embedding(dim, max_steps), persistent=False\n",
    "        )\n",
    "        self.projection1 = nn.Linear(dim * 2, proj_dim)\n",
    "        self.projection2 = nn.Linear(proj_dim, proj_dim)\n",
    "\n",
    "    def forward(self, diffusion_step):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, dim, max_steps):\n",
    "        steps = torch.arange(max_steps).unsqueeze(1)  # [T,1]\n",
    "        dims = torch.arange(dim).unsqueeze(0)  # [1,dim]\n",
    "        table = steps * 10.0 ** (dims * 4.0 / dim)  # [T,dim]\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)\n",
    "        return table\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, residual_channels, dilation):\n",
    "        super().__init__()\n",
    "        self.dilated_conv = nn.Conv1d(\n",
    "            residual_channels,\n",
    "            2 * residual_channels,\n",
    "            3,\n",
    "            padding=dilation,\n",
    "            dilation=dilation,\n",
    "            padding_mode=\"zeros\",\n",
    "        )\n",
    "        self.diffusion_projection = nn.Linear(hidden_size, residual_channels)\n",
    "        self.output_projection = nn.Conv1d(residual_channels, 2 * residual_channels, 1)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.output_projection.weight)\n",
    "\n",
    "    def forward(self, x, diffusion_step):\n",
    "        diffusion_step = self.diffusion_projection(diffusion_step).unsqueeze(-1)\n",
    "\n",
    "        y = x + diffusion_step\n",
    "        y = self.dilated_conv(y)\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)\n",
    "\n",
    "        y = self.output_projection(y)\n",
    "        y = F.leaky_relu(y, 0.4)\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        return (x + residual) / math.sqrt(2.0), skip\n",
    "\n",
    "class EpsilonThetaClass(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes = 5,\n",
    "        #cond_length,\n",
    "        time_emb_dim=16,\n",
    "        residual_layers=8,\n",
    "        residual_channels=8,\n",
    "        dilation_cycle_length=2,\n",
    "        residual_hidden=64,\n",
    "        class_emb_dim=10,\n",
    "        target_dim=1,\n",
    "        \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.class_embedding = nn.Embedding(num_classes, class_emb_dim)\n",
    "        \n",
    "        self.input_projection = nn.Conv1d(\n",
    "            1+class_emb_dim, residual_channels, 1, padding=2, padding_mode=\"zeros\"\n",
    "        )\n",
    "        self.diffusion_embedding = DiffusionEmbedding(\n",
    "            time_emb_dim, proj_dim=residual_hidden\n",
    "        )\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "            [\n",
    "                ResidualBlock(\n",
    "                    residual_channels=residual_channels,\n",
    "                    dilation=1,\n",
    "                    hidden_size=residual_hidden,\n",
    "                )\n",
    "                for i in range(residual_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.skip_projection = nn.Conv1d(residual_channels, residual_channels, 3)\n",
    "        self.output_projection = nn.Conv1d(residual_channels, target_dim, 3)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.input_projection.weight)\n",
    "        nn.init.kaiming_normal_(self.skip_projection.weight)\n",
    "        nn.init.kaiming_normal_(self.output_projection.weight)\n",
    "\n",
    "    def forward(self, inputs, time, class_labels):\n",
    "        class_embeddings = self.class_embedding(class_labels)  # [batch_size, class_emb_dim]\n",
    "        class_embeddings = class_embeddings.unsqueeze(2).expand(-1, -1, inputs.size(2))\n",
    "\n",
    "        # Concatenate class embeddings with inputs\n",
    "        inputs = torch.cat([inputs, class_embeddings], dim=1)\n",
    "\n",
    "        x = self.input_projection(inputs)\n",
    "        x = F.leaky_relu(x, 0.4)\n",
    "\n",
    "        diffusion_step = self.diffusion_embedding(time)\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_step)\n",
    "            skip.append(skip_connection)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip), dim=0) / math.sqrt(len(self.residual_layers))\n",
    "        x = self.skip_projection(x)\n",
    "        x = F.leaky_relu(x, 0.4)\n",
    "        x = self.output_projection(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from inspect import isfunction\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#  COND HAS BEEN TAKEN OUT FROM FUNCTIONS\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if val is not None:\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "\n",
    "def noise_like(shape, device, repeat=False):\n",
    "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(\n",
    "        shape[0], *((1,) * (len(shape) - 1))\n",
    "    )\n",
    "    noise = lambda: torch.randn(shape, device=device)\n",
    "    return repeat_noise() if repeat else noise()\n",
    "\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.model/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = np.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = np.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return np.clip(betas, 0, 0.999)\n",
    "\n",
    "\n",
    "class GaussianDiffusionClass(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,#pass epsilon theta\n",
    "        input_size,\n",
    "        beta_end=0.1,\n",
    "        diff_steps=100,\n",
    "        loss_type=\"l2\",\n",
    "        betas=None,\n",
    "        beta_schedule=\"linear\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.denoise_fn = denoise_fn\n",
    "        self.input_size = input_size\n",
    "        self.__scale = None\n",
    "\n",
    "        if betas is not None:\n",
    "            betas = (\n",
    "                betas.detach().cpu().numpy()\n",
    "                if isinstance(betas, torch.Tensor)\n",
    "                else betas\n",
    "            )\n",
    "        else:\n",
    "            if beta_schedule == \"linear\":\n",
    "                betas = np.linspace(1e-4, beta_end, diff_steps)\n",
    "            elif beta_schedule == \"quad\":\n",
    "                betas = np.linspace(1e-4 ** 0.5, beta_end ** 0.5, diff_steps) ** 2\n",
    "            elif beta_schedule == \"const\":\n",
    "                betas = beta_end * np.ones(diff_steps)\n",
    "            elif beta_schedule == \"jsd\":  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "                betas = 1.0 / np.linspace(diff_steps, 1, diff_steps)\n",
    "            elif beta_schedule == \"sigmoid\":\n",
    "                betas = np.linspace(-6, 6, diff_steps)\n",
    "                betas = (beta_end - 1e-4) / (np.exp(-betas) + 1) + 1e-4\n",
    "            elif beta_schedule == \"cosine\":\n",
    "                betas = cosine_beta_schedule(diff_steps)\n",
    "            else:\n",
    "                raise NotImplementedError(beta_schedule)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "\n",
    "        (timesteps,) = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32)\n",
    "\n",
    "        self.register_buffer(\"betas\", to_torch(betas))\n",
    "        self.register_buffer(\"alphas_cumprod\", to_torch(alphas_cumprod))\n",
    "        self.register_buffer(\"alphas_cumprod_prev\", to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer(\"sqrt_alphas_cumprod\", to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer(\n",
    "            \"sqrt_one_minus_alphas_cumprod\", to_torch(np.sqrt(1.0 - alphas_cumprod))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"log_one_minus_alphas_cumprod\", to_torch(np.log(1.0 - alphas_cumprod))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sqrt_recip_alphas_cumprod\", to_torch(np.sqrt(1.0 / alphas_cumprod))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sqrt_recipm1_alphas_cumprod\", to_torch(np.sqrt(1.0 / alphas_cumprod - 1))\n",
    "        )\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = (\n",
    "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "        )\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "        self.register_buffer(\"posterior_variance\", to_torch(posterior_variance))\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "        self.register_buffer(\n",
    "            \"posterior_log_variance_clipped\",\n",
    "            to_torch(np.log(np.maximum(posterior_variance, 1e-20))),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"posterior_mean_coef1\",\n",
    "            to_torch(betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod)),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"posterior_mean_coef2\",\n",
    "            to_torch(\n",
    "                (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def scale(self):\n",
    "        return self.__scale\n",
    "\n",
    "    @scale.setter\n",
    "    def scale(self, scale):\n",
    "        self.__scale = scale\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        mean = extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        variance = extract(1.0 - self.alphas_cumprod, t, x_start.shape)\n",
    "        log_variance = extract(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t\n",
    "            - extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = (\n",
    "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start\n",
    "            + extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = extract(\n",
    "            self.posterior_log_variance_clipped, t, x_t.shape\n",
    "        )\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, t, class_labels, clip_denoised: bool):\n",
    "        x_recon = self.predict_start_from_noise(\n",
    "            x, t=t, noise=self.denoise_fn(x, t, class_labels)\n",
    "        )\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1.0, 1.0)\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t\n",
    "        )\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def q_sample_loop(self,x_0, shape):\n",
    "        device = self.betas.device\n",
    "\n",
    "        b=shape[0]\n",
    "        img=torch.empty(self.num_timesteps, *shape)\n",
    "        for i in range(0, self.num_timesteps) :\n",
    "            img[i]=self.q_sample(x_0, torch.full((b,), i, device=device, dtype=torch.long))\n",
    "        return img\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, class_labels, clip_denoised=False, repeat_noise=False):\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(\n",
    "            x=x, t=t, class_labels = class_labels, clip_denoised=clip_denoised\n",
    "        )\n",
    "        noise = noise_like(x.shape, device, repeat_noise)\n",
    "        # no noise when t == 0\n",
    "        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
    "        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, x, class_labels):\n",
    "        device = self.betas.device\n",
    "\n",
    "        b = x.shape[0]\n",
    "        img = torch.randn(x.shape, device=device)\n",
    "\n",
    "        for i in reversed(range(0, self.num_timesteps)):\n",
    "            img = self.p_sample(\n",
    "                img, torch.full((b,),class_labels, i, device=device, dtype=torch.long)\n",
    "            )\n",
    "        return img\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, class_labels, sample_shape=torch.Size(), cond=None):\n",
    "        if cond is not None:\n",
    "            shape = cond.shape[:-1] + (self.input_size,)\n",
    "            # TODO reshape cond to (B*T, 1, -1)\n",
    "        else:\n",
    "            shape = sample_shape\n",
    "        x_hat = self.p_sample_loop(shape, class_labels, cond)  # TODO reshape x_hat to (B,T,-1)\n",
    "\n",
    "        if self.scale is not None:\n",
    "            x_hat *= self.scale\n",
    "        return x_hat\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def interpolate(self, x1, x2,class_labels, t=None, lam=0.5):\n",
    "        b, *_, device = *x1.shape, x1.device\n",
    "        t = default(t, self.num_timesteps - 1)\n",
    "\n",
    "        assert x1.shape == x2.shape\n",
    "\n",
    "        t_batched = torch.stack([torch.tensor(t, device=device)] * b)\n",
    "        xt1, xt2 = map(lambda x: self.q_sample(x, t=t_batched), (x1, x2))\n",
    "\n",
    "        img = (1 - lam) * xt1 + lam * xt2\n",
    "        for i in reversed(range(0, t)):\n",
    "            img = self.p_sample(\n",
    "                img, torch.full((b,), class_labels,i, device=device, dtype=torch.long)\n",
    "            )\n",
    "\n",
    "        return img\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "            + extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_start, t, class_labels, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "        x_recon = self.denoise_fn(x_noisy, t, class_labels)\n",
    "\n",
    "        if self.loss_type == \"l1\":\n",
    "            loss = F.l1_loss(x_recon, noise)\n",
    "        elif self.loss_type == \"l2\":\n",
    "            loss = F.mse_loss(x_recon, noise)\n",
    "        elif self.loss_type == \"huber\":\n",
    "            loss = F.smooth_l1_loss(x_recon, noise)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def log_prob(self, x, class_labels,*args, **kwargs):\n",
    "        if self.scale is not None:\n",
    "            x /= self.scale\n",
    "\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        time = torch.randint(0, self.num_timesteps, (B * T,), device=x.device).long()\n",
    "        loss = self.p_losses(\n",
    "            x.reshape(B * T, 1, -1),  time, class_labels,*args, **kwargs\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            net: GaussianDiffusionClass,\n",
    "            epochs: int = 50,\n",
    "            batch_size: int = 32,\n",
    "            num_batches_per_epoch: int = 50,\n",
    "            learning_rate: float = 1e-3,\n",
    "            weight_decay: float = 1e-6,\n",
    "            maximum_learning_rate: float = 1e-2,\n",
    "            model_name : str = 'model',\n",
    "            model_type : str ='torch',\n",
    "            model_save_path : str = 'model_sav_path',\n",
    "            input_size = [256],\n",
    "           \n",
    "\n",
    "            **kwargs,\n",
    "    )->None:\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches_per_epoch = num_batches_per_epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.maximum_learning_rate = maximum_learning_rate\n",
    "        self.model_name = model_name\n",
    "        self.model_type = model_type\n",
    "        self.model_save_path = model_save_path\n",
    "        self.input_size = input_size\n",
    "        self.net = net\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def __call__(\n",
    "            self,\n",
    "           \n",
    "            train_iter: DataLoader,\n",
    " \n",
    "    )->None:\n",
    "        \n",
    "        wandb.login()\n",
    "        \n",
    "        wandb.init(project=\"test_train_class\")\n",
    "\n",
    "        # Log hyperparameters and other configurations\n",
    "        config = {\n",
    "            'epochs': self.epochs,\n",
    "            'batch_size': self.batch_size,\n",
    "            'num_batches_per_epoch': self.num_batches_per_epoch,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'weight_decay': self.weight_decay,\n",
    "            'maximum_learning_rate': self.maximum_learning_rate,\n",
    "        }\n",
    "        wandb.config.update(config)\n",
    "\n",
    "        optimizer = Adam(\n",
    "            self.net.parameters(), lr = self.learning_rate, weight_decay = self.weight_decay\n",
    "        )\n",
    "\n",
    "        lr_scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr = self.maximum_learning_rate,\n",
    "            steps_per_epoch = self.num_batches_per_epoch,\n",
    "            epochs = self.epochs,\n",
    "        ) \n",
    "\n",
    "        losses_t = []\n",
    "        for epoch in range(self.epochs):\n",
    "            tic = time.time()\n",
    "            cumm_epoch_loss = 0.0\n",
    "\n",
    "            with tqdm(train_iter, total=self.num_batches_per_epoch - 1) as it:\n",
    "                for batch_no, data_entry in enumerate(it, start=1):\n",
    "                    optimizer.zero_grad()\n",
    "                    signals = data_entry['signals']\n",
    "                    class_labels = data_entry['sc']  # Ensure this is included in your model's log_prob method\n",
    "                    losses = self.net.log_prob(signals, class_labels=class_labels)\n",
    "                    cumm_epoch_loss += losses.item()\n",
    "\n",
    "                    avg_epoch_loss = cumm_epoch_loss / batch_no\n",
    "                    it.set_postfix({\"epoch\": f\"{epoch + 1}/{self.epochs}\", \"avg_loss\": avg_epoch_loss}, refresh=False)\n",
    "\n",
    "                    wandb.log({\"train_loss\": losses.item()})\n",
    "                    losses.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                \n",
    "\n",
    "                    if self.num_batches_per_epoch == batch_no:\n",
    "                        break\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_epoch_loss,\n",
    "                \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "                \"gradient_norm\": self.calculate_gradient_norm(self.net),\n",
    "                \"training_time_per_epoch\": time.time() - tic,\n",
    "            })\n",
    "            losses_t.append(avg_epoch_loss)\n",
    "        \n",
    "        self.save_model_as_artifact(self.net)\n",
    "            \n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_gradient_norm(net):\n",
    "        total_norm = 0.0\n",
    "        for param in net.parameters():\n",
    "            if param.grad is not None:\n",
    "                param_norm = param.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** 0.5\n",
    "        return total_norm\n",
    "    \n",
    "    def save_model_as_artifact(self, model):\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        # Save the model state dictionary instead of using ONNX\n",
    "        \n",
    "        if not os.path.exists(self.model_save_path):\n",
    "            os.makedirs(self.model_save_path)\n",
    "        model_path = os.path.join(self.model_save_path, f'{self.model_name}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # Create an artifact for logging to wandb\n",
    "        artifact = wandb.Artifact(self.model_name, type=self.model_type)\n",
    "        \n",
    "        # Add metadata to the artifact\n",
    "        artifact.metadata = {\n",
    "            'format': 'pytorch_state_dict',\n",
    "            'model_type': self.model_type,\n",
    "            'epochs': self.epochs,\n",
    "            'batch_size': self.batch_size,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'weight_decay': self.weight_decay,\n",
    "            'layers': [str(layer) for layer in model.children()],\n",
    "        }\n",
    "        \n",
    "        # Add the model file to the artifact\n",
    "        artifact.add_file(model_path)\n",
    "\n",
    "        # Log the artifact to wandb\n",
    "        wandb.log_artifact(artifact)\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "        \"\"\"\n",
    "        Custom collate function to reshape data into [batch size, channels, size].\n",
    "        \"\"\"\n",
    "        # Assuming your signals are originally in the shape [size]\n",
    "        # and you want to add a single channel dimension\n",
    "        signals = torch.stack([item['signals'] for item in batch]).unsqueeze(1)  # Adds a channel dimension\n",
    "        gt = torch.stack([item['gt'] for item in batch])\n",
    "        sc = torch.stack([item['sc'] for item in batch])\n",
    "        \n",
    "        return {'signals': signals, 'gt': gt, 'sc': sc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6sue0a05) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-vortex-2</strong> at: <a href='https://wandb.ai/fyp_a/test_train_class/runs/6sue0a05/workspace' target=\"_blank\">https://wandb.ai/fyp_a/test_train_class/runs/6sue0a05/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240422_123406-6sue0a05\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6sue0a05). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Alexia\\diffusion_ts\\wandb\\run-20240422_123912-mmt5qlbc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fyp_a/test_train_class/runs/mmt5qlbc/workspace' target=\"_blank\">CLASS_batch128_lr0.001_e50</a></strong> to <a href='https://wandb.ai/fyp_a/test_train_class' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fyp_a/test_train_class' target=\"_blank\">https://wandb.ai/fyp_a/test_train_class</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fyp_a/test_train_class/runs/mmt5qlbc/workspace' target=\"_blank\">https://wandb.ai/fyp_a/test_train_class/runs/mmt5qlbc/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:mmt5qlbc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CLASS_batch128_lr0.001_e50</strong> at: <a href='https://wandb.ai/fyp_a/test_train_class/runs/mmt5qlbc/workspace' target=\"_blank\">https://wandb.ai/fyp_a/test_train_class/runs/mmt5qlbc/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240422_123912-mmt5qlbc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:mmt5qlbc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Alexia\\diffusion_ts\\wandb\\run-20240422_123919-4h8nrxa3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fyp_a/test_train_class/runs/4h8nrxa3/workspace' target=\"_blank\">sage-violet-4</a></strong> to <a href='https://wandb.ai/fyp_a/test_train_class' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fyp_a/test_train_class' target=\"_blank\">https://wandb.ai/fyp_a/test_train_class</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fyp_a/test_train_class/runs/4h8nrxa3/workspace' target=\"_blank\">https://wandb.ai/fyp_a/test_train_class/runs/4h8nrxa3/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 18\u001b[0m\n\u001b[0;32m     10\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_train_class\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mmodel_name, reinit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     13\u001b[0m     net \u001b[38;5;241m=\u001b[39m net,\n\u001b[0;32m     14\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m     15\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m     16\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Ensure the current wandb run is properly closed before the next\u001b[39;00m\n\u001b[0;32m     21\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[1;32mIn[11], line 79\u001b[0m, in \u001b[0;36mTrainer.__call__\u001b[1;34m(self, train_iter)\u001b[0m\n\u001b[0;32m     77\u001b[0m signals \u001b[38;5;241m=\u001b[39m data_entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignals\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     78\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m data_entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Ensure this is included in your model's log_prob method\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m cumm_epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     82\u001b[0m avg_epoch_loss \u001b[38;5;241m=\u001b[39m cumm_epoch_loss \u001b[38;5;241m/\u001b[39m batch_no\n",
      "Cell \u001b[1;32mIn[9], line 279\u001b[0m, in \u001b[0;36mGaussianDiffusionClass.log_prob\u001b[1;34m(self, x, class_labels, *args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m B, T, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    278\u001b[0m time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, (B \u001b[38;5;241m*\u001b[39m T,), device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m--> 279\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_losses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[1;32mIn[9], line 259\u001b[0m, in \u001b[0;36mGaussianDiffusionClass.p_losses\u001b[1;34m(self, x_start, t, class_labels, noise)\u001b[0m\n\u001b[0;32m    256\u001b[0m noise \u001b[38;5;241m=\u001b[39m default(noise, \u001b[38;5;28;01mlambda\u001b[39;00m: torch\u001b[38;5;241m.\u001b[39mrandn_like(x_start))\n\u001b[0;32m    258\u001b[0m x_noisy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_sample(x_start\u001b[38;5;241m=\u001b[39mx_start, t\u001b[38;5;241m=\u001b[39mt, noise\u001b[38;5;241m=\u001b[39mnoise)\n\u001b[1;32m--> 259\u001b[0m x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    262\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39ml1_loss(x_recon, noise)\n",
      "File \u001b[1;32mc:\\Users\\Alexia\\anaconda3\\envs\\oneddif\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexia\\anaconda3\\envs\\oneddif\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 101\u001b[0m, in \u001b[0;36mEpsilonThetaClass.forward\u001b[1;34m(self, inputs, time, class_labels)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, time, class_labels):\n\u001b[1;32m--> 101\u001b[0m     class_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, class_emb_dim]\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     class_embeddings \u001b[38;5;241m=\u001b[39m class_embeddings\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Concatenate class embeddings with inputs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alexia\\anaconda3\\envs\\oneddif\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexia\\anaconda3\\envs\\oneddif\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alexia\\anaconda3\\envs\\oneddif\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexia\\anaconda3\\envs\\oneddif\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/Alexia/datasets/train_set_5classes.pth'\n",
    "dataset = torch.load(file_path)\n",
    "epochs = 50\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=custom_collate_fn)\n",
    "net = GaussianDiffusionClass(EpsilonThetaClass(), input_size = 256)\n",
    "\n",
    "model_name = f'CLASS_batch{128}_lr{0.001}_e{epochs}'\n",
    "\n",
    "# Initialize and configure wandb run\n",
    "wandb.init(project=\"test_train_class\", name=model_name, reinit=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    net = net,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.001,\n",
    "    model_name=model_name,\n",
    ")\n",
    "trainer(train_loader)\n",
    "\n",
    "# Ensure the current wandb run is properly closed before the next\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oneddif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
